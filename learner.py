import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv
import os
# from absl import logging

# Load environment variables
load_dotenv()

# Configure logging
# logging.set_verbosity(logging.ERROR)

import logging
# Configure logging
logging.basicConfig(
    filename="preptify.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger()

# Constants
API_KEY = os.getenv("GEMINI_API_KEY")
MODEL_NAME = "learnlm-1.5-pro-experimental"
DATABASE_FILE = "db/questions_db.csv"

class LearningChatbot:
    def __init__(self, api_key: str, database_file: str):
        """
        Initialize the chatbot with the API key and question database.

        Args:
            api_key (str): API key for the Gemini API.
            database_file (str): Path to the CSV database file containing questions.
        """
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name=MODEL_NAME)
        self.database = self.load_database(database_file)

    @staticmethod
    def load_database(file_path: str) -> pd.DataFrame:
        """
        Load the questions database from a CSV file.

        Args:
            file_path (str): Path to the CSV file.

        Returns:
            pd.DataFrame: Loaded DataFrame.
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Database file not found: {file_path}")
        return pd.read_csv(file_path)

    def get_relevant_questions(self, unit: str = None, topic: str = None) -> pd.DataFrame:
        """
        Retrieve relevant questions based on unit and/or topic.

        Args:
            unit (str): Unit name to filter questions.
            topic (str): Topic name to filter questions.

        Returns:
            pd.DataFrame: Filtered questions.
        """
        if unit is None and topic is None:
            return self.database

        filtered_data = self.database
        if unit:
            filtered_data = filtered_data[filtered_data["unit"].str.contains(unit, case=False, na=False, regex=False)]
        if topic:
            filtered_data = filtered_data[filtered_data["topic"].str.contains(topic, case=False, na=False, regex=False)]

        return filtered_data

    def generate_response(self, questions: pd.DataFrame) -> str:
        """
        Send questions to the Gemini API to generate a teaching plan.

        Args:
            questions (pd.DataFrame): DataFrame containing questions.

        Returns:
            str: Teaching plan generated by the model.
        """
        if questions.empty:
            return "No questions available for the selected unit or topic."

        # Prepare prompt for the Gemini model
        questions_text = "\n".join(f"Q{row['question_no']}: {row['question']}" for _, row in questions.iterrows())
        prompt = (
            f"The following are questions related to a specific topic or unit:\n\n"
            f"{questions_text}\n\n"
            "Provide detailed answers to each question, including the correct option, explanation, and any additional information."
            "Clarify the answers, and offer additional information to help the user understand the topic better."
        )

        try:
            response = self.model.generate_content(prompt)
            return response.text if response.candidates else "No valid response from the model."
        except Exception as e:
            return f"Error generating teaching plan: {e}"

    def handle_custom_question(self, question: str) -> str:
        """
        Handle a custom question from the user and generate a response.

        Args:
            question (str): Custom question provided by the user.

        Returns:
            str: The response generated by the model for the custom question.
        """
        prompt = (
            f"User asked the following question: {question}\n\n"
            "Provide a detailed explanation for the question to help the user understand the concept."
        )

        try:
            response = self.model.generate_content(prompt)
            return response.text if response.candidates else "No valid response from the model."
        except Exception as e:
            return f"Error handling custom question: {e}"

    def chat(self):
        """
        Start the chatbot interface.
        """
        print("Welcome to the Learning Chatbot! I can help you learn topics by providing explanations and quizzes.")

        while True:
            print("\nType 'exit' to quit.")

            custom_question = input("Do you have any custom question about the topic? (Enter 'yes' to ask or press Enter to skip): ").strip().lower()
            if custom_question == 'yes':
                question = input("Enter your custom question: ").strip()
                if question.lower() == "exit":
                    break
                print("Fetching answer for your custom question...\n")
                answer = self.handle_custom_question(question)
                print("\nAnswer to your question:")
                print(answer)
                continue
            
            unit = input("Enter the unit name (or press Enter to skip): ").strip()
            if unit.lower() == "exit":
                break

            topic = input("Enter the topic name (or press Enter to skip): ").strip()
            if topic.lower() == "exit":
                break

            print("Fetching relevant questions...\n")
            relevant_questions = self.get_relevant_questions(unit=unit, topic=topic)

            teaching_plan = self.generate_response(relevant_questions)
            print("\nGenerated Teaching Plan:")
            print(teaching_plan)

if __name__ == "__main__":
    try:
        chatbot = LearningChatbot(api_key=API_KEY, database_file=DATABASE_FILE)
        chatbot.chat()
    except Exception as e:
        print(f"Error: {e}")
